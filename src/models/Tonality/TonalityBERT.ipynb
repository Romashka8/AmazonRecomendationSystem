{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V-ngcQzlwKQu"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "import google.colab as colab\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import transformers as ppb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# подключим наш гугл-диск для считывания и сохранения данных\n",
        "my_drive = '/content/drive'\n",
        "colab.drive.mount(my_drive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_us4W93YuYtA",
        "outputId": "829be059-0d49-469a-80e6-d1866abb0a75"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# генератор разбиения на батчи\n",
        "# нужен для оптимизации по памяти\n",
        "class BatchGenerator:\n",
        "\n",
        "  def __init__(self, df, batch_size=2000):\n",
        "\n",
        "    self.df = df\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __iter__(self):\n",
        "\n",
        "        start = 0\n",
        "\n",
        "        while start < self.df.shape[0]:\n",
        "\n",
        "            if start + self.batch_size > self.df.shape[0]:\n",
        "                yield self.df[start:self.df.shape[0]].reset_index(drop=True)\n",
        "\n",
        "            else:\n",
        "                yield self.df[start:start + self.batch_size].reset_index(drop=True)\n",
        "\n",
        "            start += self.batch_size\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return int(np.ceil(self.df.shape[0] / self.batch_size))"
      ],
      "metadata": {
        "id": "h4AtAEI3q-wh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InferenceBERT:\n",
        "\n",
        "  allowed_models = ('distilbert-base-uncased', 'bert-base-uncased')\n",
        "\n",
        "  def __init__(self, df, batch_size, save_path, model_name='distilbert-base-uncased'):\n",
        "\n",
        "    # зададим процессор и генератор батчей\n",
        "    self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    self.batches = BatchGenerator(df, batch_size)\n",
        "\n",
        "    # Загрузим bert и его токенайзер\n",
        "    assert model_name in self.allowed_models\n",
        "    self.model_name = model_name\n",
        "    self.tokenizer = ppb.AutoTokenizer.from_pretrained(self.model_name)\n",
        "    self.bert_model = ppb.AutoModel.from_pretrained(self.model_name).to(self.device)\n",
        "\n",
        "    # настроим эпохи\n",
        "    self.epoch = 0\n",
        "    self.max_epoch = len(self.batches)\n",
        "\n",
        "    # папка для сохранения результата\n",
        "    self.save_path = save_path\n",
        "\n",
        "  def __del__(self):\n",
        "    del self.bert_model, self.tokenizer, self.batches\n",
        "\n",
        "  def inference(self, start, end):\n",
        "\n",
        "    assert end <= self.max_epoch\n",
        "\n",
        "    # Прогоняем данные через модель\n",
        "    loop = tqdm.tqdm(self.batches, leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "\n",
        "      if start <= self.epoch < end:\n",
        "          # Токенизация батча\n",
        "          tokenized = batch[0].apply((\n",
        "              lambda x: self.tokenizer.encode(x, add_special_tokens=True,\n",
        "                                              truncation=True, max_length=512)\n",
        "          ))\n",
        "\n",
        "          max_len = 0\n",
        "          for i in tokenized.values:\n",
        "            if len(i) > max_len:\n",
        "              max_len = len(i)\n",
        "\n",
        "          padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized.values])\n",
        "          attention_mask = np.where(padded != 0, 1, 0)\n",
        "\n",
        "          input_ids = torch.tensor(padded).to(self.device)\n",
        "          attention_mask = torch.tensor(attention_mask).to(self.device)\n",
        "\n",
        "          # try:\n",
        "\n",
        "          with torch.no_grad():\n",
        "              last_hidden_states = self.bert_model(\n",
        "                  input_ids, attention_mask=attention_mask\n",
        "              )\n",
        "\n",
        "          del input_ids, attention_mask\n",
        "\n",
        "          # Извлечение эмбеддингов последнего скрытого слоя\n",
        "          features = last_hidden_states[0][:, 0, :].cpu().numpy()\n",
        "\n",
        "            # Сохраним эмбединг\n",
        "          pd.concat(\n",
        "              [\n",
        "                pd.DataFrame(features),\n",
        "                pd.DataFrame(batch[1].values, columns=['target'])\n",
        "              ], axis=1\n",
        "            ).to_csv(os.path.join(self.save_path, f'state_epoch_{self.epoch}.csv'))\n",
        "\n",
        "          self.epoch += 1\n",
        "\n",
        "          # except RuntimeError:\n",
        "\n",
        "            # print(input_ids.size(), attention_mask.size())\n",
        "\n",
        "      else:\n",
        "          print('All bathes embeded!')\n",
        "          break\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "hAK26b_ZzH-c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# в репозитории архив находится тут: https://github.com/Romashka8/AmazonRecomendationSystem/tree/main/data/raw/tonality\n",
        "# загрузим его с другого github-а - https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv\n",
        "TONALITY_PATH = 'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv'\n",
        "EXTENDED_REVIEWS_PATH = '/content/drive/MyDrive/colab_data/ExtendedReviewsForBERT/reviews_with_goods.csv'\n",
        "\n",
        "# настройка путей для сохранения\n",
        "SAVE_PATH = '/content/drive/MyDrive/colab_data'\n",
        "SAVE_TONALITY = 'TonalityBERTStates'\n",
        "SAVE_REVIEWS = 'RewievsEmbedded'\n",
        "\n",
        "for path in (SAVE_TONALITY, SAVE_REVIEWS):\n",
        "\n",
        "  check_exists = os.path.join(SAVE_PATH, path)\n",
        "\n",
        "  if not os.path.exists(check_exists):\n",
        "    os.mkdir(check_exists)"
      ],
      "metadata": {
        "id": "_iANMOL8wXXE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовим и посмотрим данные"
      ],
      "metadata": {
        "id": "qhHSBmDmw0my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tonality = pd.read_csv(TONALITY_PATH, delimiter='\\t', header=None)\n",
        "df_reviews = pd.read_csv(EXTENDED_REVIEWS_PATH).dropna()\n",
        "df_reviews.reset_index(inplace=True)\n",
        "# для обработки возьмем только текст и id\n",
        "df_reviews_bert_ids, df_reviews_bert_text = df_reviews['user_id'].copy(), df_reviews['text'].copy()\n",
        "df_reviews_bert = pd.concat(\n",
        "    [df_reviews_bert_text, pd.DataFrame(np.zeros(df_reviews_bert_ids.shape[0]))],\n",
        "    axis=1\n",
        ")\n",
        "df_reviews_bert.columns = [0, 1]"
      ],
      "metadata": {
        "id": "6SwL-dRjw5BV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовим Эмбединги"
      ],
      "metadata": {
        "id": "UZ5gz_sC9dTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tonality_bert = InferenceBERT(df_tonality, 2000, os.path.join(SAVE_PATH, SAVE_TONALITY))\n",
        "tonality_bert.inference(0, 4)\n",
        "del tonality_bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXyPLJUexZk1",
        "outputId": "502409b1-cccc-4045-fa5a-0f75b3a16e5f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_bert = InferenceBERT(df_reviews_bert, 100, os.path.join(SAVE_PATH, SAVE_REVIEWS))\n",
        "reviews_bert.inference(0, 84)\n",
        "del reviews_bert"
      ],
      "metadata": {
        "id": "b09hqqVZzF5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сохраним файлы"
      ],
      "metadata": {
        "id": "Kdng8u1d3q1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/colab_data"
      ],
      "metadata": {
        "id": "KRP3FNVs3uwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r TonalityBERTStates.zip TonalityBERTStates/\n",
        "! zip -r TonalityBERTStates.zip RewievsEmbedded/"
      ],
      "metadata": {
        "id": "fAwZuQHZ35q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colab.files.download('TonalityBERTStates.zip')\n",
        "colab.files.download('RewievsEmbedded.zip')"
      ],
      "metadata": {
        "id": "LjuTplBj4zWf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}